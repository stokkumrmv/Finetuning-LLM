{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjs8BloQkkmxHiW2Mxa+dc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stokkumrmv/Finetuning-LLM/blob/main/Generating_Prompts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import pandas as pd\n",
        "import openai\n",
        "import time\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuuNqy1ls6kY",
        "outputId": "5408f6ae-6e1c-4191-b7e2-494492925a02"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your OpenAI API credentials here\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_key = \"1fb7adbb3d1649389c37ab810ccd309d\"\n",
        "openai.api_base = \"https://kip-functional-ai.openai.azure.com/\"\n",
        "openai.api_version = \"2023-05-15\"  # subject to change\n",
        "\n"
      ],
      "metadata": {
        "id": "1hkWTOkMtDO8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty DataFrame with appropriate columns\n",
        "columns = ['question', 'answer', 'Abstract']\n",
        "Scaling_Scopus = pd.DataFrame(columns=columns)\n"
      ],
      "metadata": {
        "id": "QBZpPg8Fv38C"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the following list of abstracts with your actual data\n",
        "list_of_abstracts = [\n",
        "    \"In the present article, we present a means to remotely and transparently estimate an individual’s level of fatigue by quantifying changes in his or her voice characteristics. Using Voice analysis to estimate fatigue is unique from established cognitive measures in a number of ways: (1) speaking is a natural activity requiring no initial training or learning curve, (2) voice recording is a unobtrusive operation allowing the speakers to go about their normal work activities, (3) using telecommunication infrastructure (radio, telephone, etc.) a diffuse set of remote populations can be monitored at a central location, and (4) often, previously recorded voice data are available for post hoc analysis. By quantifying changes in the mathematical coefficients that describe the human speech production process, we were able to demonstrate that for speech sounds requiring a large average air flow, a speaker’s voice changes in synchrony with both direct measures of fatigue and with changes predicted by the length of time awake.\",\n",
        "    \"Quantifying neurological disorders from voice is a rapidly growing field of research and holds promise for unobtrusive and large-scale disorder monitoring. The data recording setup and data analysis pipelines are both crucial aspects to effectively obtain relevant information from participants. Therefore, we performed a systematic review to provide a high-level overview of practices across various neurological disorders and highlight emerging trends. PRISMA-based literature searches were conducted through PubMed, Web of Science, and IEEE Xplore to identify publications in which original (i.e., newly recorded) datasets were collected. Disorders of interest were psychiatric as well as neurodegenerative disorders, such as bipolar disorder, depression, and stress, as well as amyotrophic lateral sclerosis amyotrophic lateral sclerosis, Alzheimer's, and Parkinson's disease, and speech impairments (aphasia, dysarthria, and dysphonia). Of the 43 retrieved studies, Parkinson's disease is represented most prominently with 19 discovered datasets. Free speech and read speech tasks are most commonly used across disorders. Besides popular feature extraction toolkits, many studies utilise custom-built feature sets. Correlations of acoustic features with psychiatric and neurodegenerative disorders are presented. In terms of analysis, statistical analysis for significance of individual features is commonly used, as well as predictive modeling approaches, especially with support vector machines and a small number of artificial neural networks. An emerging trend and recommendation for future studies is to collect data in everyday life to facilitate longitudinal data collection and to capture the behavior of participants more naturally. Another emerging trend is to record additional modalities to voice, which can potentially increase analytical performance.\",\n",
        "    \"Abstract: Background: Experimental studies using qualitative or quantitative analysis have demonstrated that the human voice progressively worsens with ageing. These studies, however, have mostly focused on specific voice features without examining their dynamic interaction. To examine the complexity of age-related changes in voice, more advanced techniques based on machine learning have been recently applied to voice recordings but only in a laboratory setting. We here recorded voice samples in a large sample of healthy subjects. To improve the ecological value of our analysis, we collected voice samples directly at home using smartphones. Methods: 138 younger adults (65 males and 73 females, age range: 15–30) and 123 older adults (47 males and 76 females, age range: 40–85) produced a sustained emission of a vowel and a sentence. The recorded voice samples underwent a machine learning analysis through a support vector machine algorithm. Results: The machine learning analysis of voice samples from both speech tasks discriminated between younger and older adults, and between males and females, with high statistical accuracy. Conclusions: By recording voice samples through smartphones in an ecological setting, we demonstrated the combined effect of age and gender on voice. Our machine learning analysis demonstrates the effect of ageing on voice.\"\n",
        "    # Add more abstracts here\n",
        "]"
      ],
      "metadata": {
        "id": "QJImiM1JtO2R"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new try\n",
        "\n",
        "def generate_question_and_answer(row):\n",
        "   if pd.isnull(row['question']) or pd.isnull(row['answer']):\n",
        "    for _ in range(5):  # Retry up to 5 times\n",
        "        try:\n",
        "            # Use the Chat API to generate a question\n",
        "            question_message = openai.ChatCompletion.create(\n",
        "                # model=\"gpt-3.5-turbo\",\n",
        "                #  engine=\"text-davinci-002\",\n",
        "                deployment_id=\"gpt-35-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a scientist that generates questions from scientific abstracts about voice recordings and mental health\"},\n",
        "                    {\"role\": \"user\", \"content\": row['Abstract']},\n",
        "                ],\n",
        "            ).choices[0]['message']['content']\n",
        "\n",
        "            # Now generate the answer\n",
        "            answer_message = openai.ChatCompletion.create(\n",
        "                # model=\"gpt-3.5-turbo\",\n",
        "                # engine=\"text-davinci-002\",\n",
        "                deployment_id=\"gpt-35-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a knowledgeable scientist specialized in voice recordings and mental health.\"},\n",
        "                    {\"role\": \"user\", \"content\": question_message},\n",
        "                ],\n",
        "            ).choices[0]['message']['content']\n",
        "\n",
        "\n",
        "\n",
        "        except openai.error.ServiceUnavailableError:\n",
        "            print(\"OpenAI server is busy, waiting for 60 seconds before retrying...\")\n",
        "            time.sleep(60)  # Wait for 60 seconds before retrying\n",
        "        else:\n",
        "            # If the request was successful, save the question and answer in the DataFrame\n",
        "            Scaling_Scopus.at[row.name, 'question'] = question_message\n",
        "            Scaling_Scopus.at[row.name, 'answer'] = answer_message\n",
        "\n",
        "\n",
        "\n",
        "            # Optionally, save the DataFrame to a file after each successful request\n",
        "            Scaling_Scopus.to_csv('abstracts_with_questions_and_answers.csv', index=False, sep = \";\")\n",
        "\n",
        "\n",
        "\n",
        "            break  # Break the loop if the request was successful\n",
        "        # delay between requests\n",
        "        time.sleep(2)\n"
      ],
      "metadata": {
        "id": "rHGpMl8nyBQH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty DataFrame with appropriate columns\n",
        "columns = ['question', 'answer', 'Abstract']\n",
        "Scaling_Scopus = pd.DataFrame(columns=columns)\n",
        "\n",
        "# Replace the following list of abstracts with your actual data\n",
        "list_of_abstracts = [\n",
        "    \"In the present article, we present a means to remotely and transparently estimate an individual’s level of fatigue by quantifying changes in his or her voice characteristics. Using Voice analysis to estimate fatigue is unique from established cognitive measures in a number of ways: (1) speaking is a natural activity requiring no initial training or learning curve, (2) voice recording is a unobtrusive operation allowing the speakers to go about their normal work activities, (3) using telecommunication infrastructure (radio, telephone, etc.) a diffuse set of remote populations can be monitored at a central location, and (4) often, previously recorded voice data are available for post hoc analysis. By quantifying changes in the mathematical coefficients that describe the human speech production process, we were able to demonstrate that for speech sounds requiring a large average air flow, a speaker’s voice changes in synchrony with both direct measures of fatigue and with changes predicted by the length of time awake.\",\n",
        "    \"Quantifying neurological disorders from voice is a rapidly growing field of research and holds promise for unobtrusive and large-scale disorder monitoring. The data recording setup and data analysis pipelines are both crucial aspects to effectively obtain relevant information from participants. Therefore, we performed a systematic review to provide a high-level overview of practices across various neurological disorders and highlight emerging trends. PRISMA-based literature searches were conducted through PubMed, Web of Science, and IEEE Xplore to identify publications in which original (i.e., newly recorded) datasets were collected. Disorders of interest were psychiatric as well as neurodegenerative disorders, such as bipolar disorder, depression, and stress, as well as amyotrophic lateral sclerosis amyotrophic lateral sclerosis, Alzheimer's, and Parkinson's disease, and speech impairments (aphasia, dysarthria, and dysphonia). Of the 43 retrieved studies, Parkinson's disease is represented most prominently with 19 discovered datasets. Free speech and read speech tasks are most commonly used across disorders. Besides popular feature extraction toolkits, many studies utilise custom-built feature sets. Correlations of acoustic features with psychiatric and neurodegenerative disorders are presented. In terms of analysis, statistical analysis for significance of individual features is commonly used, as well as predictive modeling approaches, especially with support vector machines and a small number of artificial neural networks. An emerging trend and recommendation for future studies is to collect data in everyday life to facilitate longitudinal data collection and to capture the behavior of participants more naturally. Another emerging trend is to record additional modalities to voice, which can potentially increase analytical performance.\",\n",
        "    \"Abstract: Background: Experimental studies using qualitative or quantitative analysis have demonstrated that the human voice progressively worsens with ageing. These studies, however, have mostly focused on specific voice features without examining their dynamic interaction. To examine the complexity of age-related changes in voice, more advanced techniques based on machine learning have been recently applied to voice recordings but only in a laboratory setting. We here recorded voice samples in a large sample of healthy subjects. To improve the ecological value of our analysis, we collected voice samples directly at home using smartphones. Methods: 138 younger adults (65 males and 73 females, age range: 15–30) and 123 older adults (47 males and 76 females, age range: 40–85) produced a sustained emission of a vowel and a sentence. The recorded voice samples underwent a machine learning analysis through a support vector machine algorithm. Results: The machine learning analysis of voice samples from both speech tasks discriminated between younger and older adults, and between males and females, with high statistical accuracy. Conclusions: By recording voice samples through smartphones in an ecological setting, we demonstrated the combined effect of age and gender on voice. Our machine learning analysis demonstrates the effect of ageing on voice.\"\n",
        "    # Add more abstracts here\n",
        "]\n",
        "\n",
        "# Loop through the list of abstracts and generate questions and answers\n",
        "for abstract in list_of_abstracts:\n",
        "    # Create a new row with the abstract\n",
        "    new_row = {'Abstract': abstract, 'question': None, 'answer': None}\n",
        "\n",
        "    # Append the new row to the DataFrame\n",
        "    Scaling_Scopus = Scaling_Scopus.append(new_row, ignore_index=True)\n",
        "\n",
        "    # Generate the question and answer for the row\n",
        "    generate_question_and_answer(Scaling_Scopus.iloc[-1])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "Q9pj-oKb0BTv",
        "outputId": "75df4c1a-fd34-4ee8-c324-a263b11f89ef"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-66b1e6afeb27>:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  Scaling_Scopus = Scaling_Scopus.append(new_row, ignore_index=True)\n",
            "<ipython-input-50-66b1e6afeb27>:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  Scaling_Scopus = Scaling_Scopus.append(new_row, ignore_index=True)\n",
            "<ipython-input-50-66b1e6afeb27>:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  Scaling_Scopus = Scaling_Scopus.append(new_row, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-66b1e6afeb27>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScaling_Scopus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PROMPTS.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PROMPTS.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Display the resulting DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, save the DataFrame to a CSV file after generating all questions and answers\n",
        "# Save the DataFrame to a CSV file after generating all questions and answers\n",
        "Scaling_Scopus.to_csv('/content/abstracts_with_questions_and_answers.csv', index=False, sep=\";\")\n",
        "\n",
        "df = Scaling_Scopus\n",
        "df.to_csv('PROMPTS.csv', index=False)\n",
        "files.download(\"PROMPTS.csv\")\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "print(Scaling_Scopus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "z-wdfOQz0iVh",
        "outputId": "ec752e0b-5b39-4b87-9bd7-3a63fdf4d68c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_05280df7-00f6-4e7f-bd94-46d1ec9eb755\", \"PROMPTS.csv\", 14135)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            question  \\\n",
            "0  1. How reliable is using voice analysis to est...   \n",
            "1  1. What is the significance of quantifying neu...   \n",
            "2  1. How does age affect the human voice, and ho...   \n",
            "\n",
            "                                              answer  \\\n",
            "0  1. Using voice analysis to estimate an individ...   \n",
            "1  1. The significance of quantifying neurologica...   \n",
            "2  1. Age has a profound effect on the human voic...   \n",
            "\n",
            "                                            Abstract  \n",
            "0  In the present article, we present a means to ...  \n",
            "1  Quantifying neurological disorders from voice ...  \n",
            "2  Abstract: Background: Experimental studies usi...  \n"
          ]
        }
      ]
    }
  ]
}